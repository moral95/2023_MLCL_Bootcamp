{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMdv/vhfRukZ/hI4+nJsyN8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Transformer Chatbot\n","\n","\n","Implemented by Suyoung Kim, MLCL, 2023.02.13 (persistence7388@gmail.com)"],"metadata":{"id":"qtjK8UR1gftL"}},{"cell_type":"code","source":["! pip install sentencepiece "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"plhc-849NImU","executionInfo":{"status":"ok","timestamp":1676254666659,"user_tz":-540,"elapsed":3420,"user":{"displayName":"김수영","userId":"09235899458207981129"}},"outputId":"51fdb2c6-2222-4bac-ebb9-f6473ec0666a"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n"]}]},{"cell_type":"code","execution_count":19,"metadata":{"id":"PoV9aBaLNA8K","executionInfo":{"status":"ok","timestamp":1676254672002,"user_tz":-540,"elapsed":2,"user":{"displayName":"김수영","userId":"09235899458207981129"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import torch \n","import sentencepiece as spm\n","import sys\n","from tqdm import tqdm\n","from torch.nn import Transformer\n","from torch import nn\n","import math\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","source":["#Hyperparameter\n","MAX_LENGTH = 40\n","BATCH_SIZE = 64\n","lr = 1e-4\n","embed_size = 256 \n","n_head=8\n","n_hid = 512\n","n_layer = 2\n","dropout = 0.1\n","epoch = 30\n","\n","#seed\n","random_seed = 9712\n","torch.manual_seed(random_seed)\n","torch.backends.cudnn.enabled = False\n","print(torch.randn(1, 3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xwUwz_QLNWB5","executionInfo":{"status":"ok","timestamp":1676254673802,"user_tz":-540,"elapsed":3,"user":{"displayName":"김수영","userId":"09235899458207981129"}},"outputId":"c9b11773-0022-4c76-bbd5-a08838b436d0"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.3936, 0.5584, 0.9692]])\n"]}]},{"cell_type":"code","source":["#GPU\n","! nvidia-smi\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5TZq4suPJi87","outputId":"ab3685b4-b794-4510-dc25-b2f98a989966","executionInfo":{"status":"ok","timestamp":1676254676624,"user_tz":-540,"elapsed":4,"user":{"displayName":"김수영","userId":"09235899458207981129"}}},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Feb 13 02:17:55 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   68C    P0    32W /  70W |    648MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A      2903      C                                     645MiB |\n","+-----------------------------------------------------------------------------+\n","cuda\n"]}]},{"cell_type":"code","source":["# Data \n","train_data = pd.read_csv('https://raw.githubusercontent.com/Doheon/Chatbot-Transformer/main/ChatBotData.csv')\n","\n","questions = []\n","for sentence in train_data['Q']:\n","    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n","    sentence = sentence.strip()\n","    questions.append(sentence)\n","\n","\n","answers = []\n","for sentence in train_data['A']:\n","    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n","    sentence = sentence.strip()\n","    answers.append(sentence)\n","\n","with open('all.txt', 'w', encoding='utf8') as f:\n","    f.write('\\n'.join(questions))\n","    f.write('\\n'.join(answers))\n","\n","\n","corpus = \"all.txt\"\n","prefix = \"chatbot\"\n","vocab_size = 16000\n","spm.SentencePieceTrainer.train(\n","    f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" + \n","    \"--min_frequency={3}\"+\n","    \" --model_type=bpe\" +\n","    \" --max_sentence_length=999999\" + # 문장 최대 길이\n","    \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n","    \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n","    \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n","    \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n","    \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # 사용자 정의 토큰\n","\n","vocab_file = \"chatbot.model\"\n","vocab = spm.SentencePieceProcessor()\n","vocab.load(vocab_file)\n","line = \"안녕하세요 만나서 반갑습니다\"\n","pieces = vocab.encode_as_pieces(line)\n","ids = vocab.encode_as_ids(line)\n","\n","\n","print(line)\n","print(pieces)\n","print(ids)\n","print(vocab.GetPieceSize())\n","vocab_size = vocab.GetPieceSize()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fcO9dxMNNKyJ","executionInfo":{"status":"ok","timestamp":1676254687526,"user_tz":-540,"elapsed":7769,"user":{"displayName":"김수영","userId":"09235899458207981129"}},"outputId":"533a43d5-0e15-4c0e-b6af-fb7117439384"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["안녕하세요 만나서 반갑습니다\n","['▁안녕하세요', '▁만나서', '▁반갑습니다']\n","[4626, 1930, 8499]\n","16007\n"]}]},{"cell_type":"code","source":["\n","START_TOKEN = [2]\n","END_TOKEN = [3]\n","\n","#tokenize and padding  \n","\n","def tokenize_and_filter(inputs, outputs):\n","  tokenized_inputs, tokenized_outputs = [], []\n","  for (sentence1, sentence2) in zip(inputs, outputs):\n","    zeros1 = np.zeros(MAX_LENGTH, dtype=int)\n","    zeros2 = np.zeros(MAX_LENGTH, dtype=int)\n","    sentence1 = START_TOKEN + vocab.encode_as_ids(sentence1) + END_TOKEN\n","    zeros1[:len(sentence1)] = sentence1[:MAX_LENGTH]\n","\n","    sentence2 = START_TOKEN + vocab.encode_as_ids(sentence2) + END_TOKEN\n","    zeros2[:len(sentence2)] = sentence2[:MAX_LENGTH]\n","\n","    tokenized_inputs.append(zeros1)\n","    tokenized_outputs.append(zeros2)\n","  return tokenized_inputs, tokenized_outputs\n","\n","questions_encode, answers_encode = tokenize_and_filter(questions, answers)\n","print(questions_encode[0])\n","print(answers_encode[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FNjK74iCPsKg","executionInfo":{"status":"ok","timestamp":1676254690666,"user_tz":-540,"elapsed":1053,"user":{"displayName":"김수영","userId":"09235899458207981129"}},"outputId":"eef27a5f-8810-4622-a490-4ac7bf45d36a"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["[    2  5566 14968  3210   111     3     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0]\n","[   2 5192  217 5936    7    3    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0]\n"]}]},{"cell_type":"code","source":["\n","class MyDataset(Dataset):\n","    def __init__(self, questions, answers):\n","        questions = np.array(questions)\n","        answers = np.array(answers)\n","        self.inputs = questions\n","        self.dec_inputs = answers[:,:-1] #(datanum, max_len-1)\n","        self.outputs = answers[:,1:] #(datanum, max_len-1) \n","        self.length = len(questions) #input_length \n","    \n","    def __getitem__(self,idx):\n","        return (self.inputs[idx], self.dec_inputs[idx], self.outputs[idx])\n","\n","    def __len__(self):\n","        return self.length\n","\n","\n","dataset = MyDataset(questions_encode, answers_encode)\n","dataloader = DataLoader(dataset, shuffle=True, batch_size=BATCH_SIZE)\n","print(f\"data set num: {len(dataset)}\")\n","print(f\"data set num: {len(dataloader)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DFDhFCN8RmlO","executionInfo":{"status":"ok","timestamp":1676254698600,"user_tz":-540,"elapsed":541,"user":{"displayName":"김수영","userId":"09235899458207981129"}},"outputId":"532a6cda-894e-434f-c0cb-683868472830"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["data set num: 11823\n","data set num: 185\n"]}]},{"cell_type":"code","source":["class TransformerModel(nn.Module):\n","    def __init__(self, vocab_size, embed_size, n_head, n_hid, n_layer, dropout=0.5):\n","        super(TransformerModel, self).__init__()\n","        self.transformer = Transformer(embed_size, n_head, dim_feedforward=n_hid, num_encoder_layers=n_layer, num_decoder_layers=n_layer,dropout=dropout)\n","        self.e_pos = PositionalEncoding(embed_size, dropout)\n","        self.e_embedding = nn.Embedding(vocab_size, embed_size)\n","        self.d_pos = PositionalEncoding(embed_size, dropout)\n","        self.encoder_d = nn.Embedding(vocab_size, embed_size)\n","        self.embed_size = embed_size\n","        self.vocab_size = vocab_size\n","        self.linear = nn.Linear(embed_size, vocab_size)\n","        self.init_weights()\n","\n","    def generate_square_subsequent_mask(self, sz):\n","        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n","        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","        return mask\n","\n","    def init_weights(self):\n","        initrange = 0.1\n","        self.e_embedding.weight.data.uniform_(-initrange, initrange)\n","\n","    def forward(self, src, tgt, srcmask, tgtmask, srcpadmask, tgtpadmask):\n","        src = self.e_embedding(src) * math.sqrt(self.embed_size) #(batch_size, max_len, embed_size)\n","        src = self.e_pos(src) #(batch_size, max_len, embed_size)\n","        tgt = self.encoder_d(tgt) * math.sqrt(self.embed_size)#(batch_size, max_len-1, embed_size)\n","        tgt = self.d_pos(tgt)#(batch_size, max_len-1, embed_size)\n","        output = self.transformer(src.transpose(0,1), tgt.transpose(0,1), srcmask, tgtmask, src_key_padding_mask=srcpadmask, tgt_key_padding_mask=tgtpadmask) #(max_len-1, batch_size,embed_size)\n","        output = self.linear(output) #???\n","        return output\n","\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:x.size(0), :]\n","        return self.dropout(x)\n","\n","def gen_attention_mask(x):\n","    mask = torch.eq(x, 0)\n","    return mask\n","    \n","model = TransformerModel(vocab_size, embed_size=embed_size, n_head=n_head, n_hid=n_hid, n_layer=n_layer, dropout=dropout).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)"],"metadata":{"id":"5fHwIw1gTxgt","executionInfo":{"status":"ok","timestamp":1676254709991,"user_tz":-540,"elapsed":684,"user":{"displayName":"김수영","userId":"09235899458207981129"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["\n","\n","model.train()\n","for i in range(epoch):\n","    batchloss = 0.0\n","    progress = tqdm(dataloader)\n","    for (inputs, dec_inputs, outputs) in progress:\n","        optimizer.zero_grad()\n","        src_mask = model.generate_square_subsequent_mask(MAX_LENGTH).to(device) #(max_len, max_len)\n","        src_padding_mask = gen_attention_mask(inputs).to(device) #(batch_size, max_len)\n","        tgt_mask = model.generate_square_subsequent_mask(MAX_LENGTH-1).to(device)  #(max_len-1, max_len-1)\n","        tgt_padding_mask = gen_attention_mask(dec_inputs).to(device) #(batch_size, max_len-1)\n","        result = model(inputs.to(device), dec_inputs.to(device), src_mask, tgt_mask, src_padding_mask,tgt_padding_mask) #(max_len, batch_size, vocab_size)\n","        loss = criterion(result.permute(1,2,0), outputs.to(device).long())\n","        loss.backward()\n","        optimizer.step()\n","        batchloss += loss\n","        progress.set_description(\"{:0.3f}\".format(loss))\n","    print(\"epoch:\",i+1,\"|\",\"loss:\",batchloss.cpu().item() / len(dataloader))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IxpaKcCiXQ5j","executionInfo":{"status":"ok","timestamp":1676255106545,"user_tz":-540,"elapsed":394452,"user":{"displayName":"김수영","userId":"09235899458207981129"}},"outputId":"b5022b1d-2ad1-4f86-8d38-ed7388bae0df"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["1.007: 100%|██████████| 185/185 [00:15<00:00, 11.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 1 | loss: 1.7898976918813345\n"]},{"output_type":"stream","name":"stderr","text":["0.886: 100%|██████████| 185/185 [00:13<00:00, 14.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 2 | loss: 0.9690366177945524\n"]},{"output_type":"stream","name":"stderr","text":["0.962: 100%|██████████| 185/185 [00:13<00:00, 14.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 3 | loss: 0.9122519003378379\n"]},{"output_type":"stream","name":"stderr","text":["1.088: 100%|██████████| 185/185 [00:13<00:00, 13.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 4 | loss: 0.8844849457611909\n"]},{"output_type":"stream","name":"stderr","text":["0.916: 100%|██████████| 185/185 [00:12<00:00, 14.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 5 | loss: 0.8619559623099662\n"]},{"output_type":"stream","name":"stderr","text":["0.867: 100%|██████████| 185/185 [00:12<00:00, 14.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 6 | loss: 0.8416794235641892\n"]},{"output_type":"stream","name":"stderr","text":["0.874: 100%|██████████| 185/185 [00:13<00:00, 13.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 7 | loss: 0.8226193814664273\n"]},{"output_type":"stream","name":"stderr","text":["0.810: 100%|██████████| 185/185 [00:13<00:00, 14.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 8 | loss: 0.8030934101826436\n"]},{"output_type":"stream","name":"stderr","text":["0.812: 100%|██████████| 185/185 [00:13<00:00, 14.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 9 | loss: 0.7833251953125\n"]},{"output_type":"stream","name":"stderr","text":["0.824: 100%|██████████| 185/185 [00:13<00:00, 14.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 10 | loss: 0.7635618467588683\n"]},{"output_type":"stream","name":"stderr","text":["0.786: 100%|██████████| 185/185 [00:12<00:00, 14.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 11 | loss: 0.742910436681799\n"]},{"output_type":"stream","name":"stderr","text":["0.758: 100%|██████████| 185/185 [00:12<00:00, 14.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 12 | loss: 0.721995008313978\n"]},{"output_type":"stream","name":"stderr","text":["0.666: 100%|██████████| 185/185 [00:12<00:00, 14.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 13 | loss: 0.7009164346230997\n"]},{"output_type":"stream","name":"stderr","text":["0.727: 100%|██████████| 185/185 [00:12<00:00, 14.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 14 | loss: 0.6803545977618243\n"]},{"output_type":"stream","name":"stderr","text":["0.541: 100%|██████████| 185/185 [00:12<00:00, 14.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 15 | loss: 0.6586325155722128\n"]},{"output_type":"stream","name":"stderr","text":["0.532: 100%|██████████| 185/185 [00:12<00:00, 14.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 16 | loss: 0.6373852704022381\n"]},{"output_type":"stream","name":"stderr","text":["0.515: 100%|██████████| 185/185 [00:12<00:00, 14.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 17 | loss: 0.6150159268765836\n"]},{"output_type":"stream","name":"stderr","text":["0.599: 100%|██████████| 185/185 [00:12<00:00, 14.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 18 | loss: 0.5933079075168919\n"]},{"output_type":"stream","name":"stderr","text":["0.547: 100%|██████████| 185/185 [00:13<00:00, 14.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 19 | loss: 0.5709849589579814\n"]},{"output_type":"stream","name":"stderr","text":["0.602: 100%|██████████| 185/185 [00:13<00:00, 14.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 20 | loss: 0.5495030171162373\n"]},{"output_type":"stream","name":"stderr","text":["0.609: 100%|██████████| 185/185 [00:13<00:00, 14.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 21 | loss: 0.5264011279956714\n"]},{"output_type":"stream","name":"stderr","text":["0.613: 100%|██████████| 185/185 [00:13<00:00, 14.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 22 | loss: 0.5046579721811656\n"]},{"output_type":"stream","name":"stderr","text":["0.534: 100%|██████████| 185/185 [00:13<00:00, 14.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 23 | loss: 0.4821989729597762\n"]},{"output_type":"stream","name":"stderr","text":["0.451: 100%|██████████| 185/185 [00:13<00:00, 14.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 24 | loss: 0.4594645319758235\n"]},{"output_type":"stream","name":"stderr","text":["0.441: 100%|██████████| 185/185 [00:12<00:00, 14.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 25 | loss: 0.43746416246568837\n"]},{"output_type":"stream","name":"stderr","text":["0.413: 100%|██████████| 185/185 [00:12<00:00, 14.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 26 | loss: 0.41619823558910474\n"]},{"output_type":"stream","name":"stderr","text":["0.476: 100%|██████████| 185/185 [00:12<00:00, 14.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 27 | loss: 0.39479922732791384\n"]},{"output_type":"stream","name":"stderr","text":["0.385: 100%|██████████| 185/185 [00:13<00:00, 14.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 28 | loss: 0.37386474609375\n"]},{"output_type":"stream","name":"stderr","text":["0.397: 100%|██████████| 185/185 [00:13<00:00, 14.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 29 | loss: 0.35309072958456506\n"]},{"output_type":"stream","name":"stderr","text":["0.227: 100%|██████████| 185/185 [00:13<00:00, 14.14it/s]"]},{"output_type":"stream","name":"stdout","text":["epoch: 30 | loss: 0.3333302265888936\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), \"chatbot.pth\")"],"metadata":{"id":"bS8Ck3RSd15o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess_sentence(sentence):\n","    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n","    sentence = sentence.strip()\n","    return sentence\n","\n","def evaluate(sentence):\n","    sentence = preprocess_sentence(sentence)\n","    input = torch.tensor([START_TOKEN + vocab.encode_as_ids(sentence) + END_TOKEN]).to(device)\n","    output = torch.tensor([START_TOKEN]).to(device)\n","\n","    model.eval()\n","    for i in range(MAX_LENGTH):\n","        #mask \n","        src_mask = model.generate_square_subsequent_mask(input.shape[1]).to(device)\n","        tgt_mask = model.generate_square_subsequent_mask(output.shape[1]).to(device)\n","        src_padding_mask = gen_attention_mask(input).to(device)\n","        tgt_padding_mask = gen_attention_mask(output).to(device)\n","\n","        predictions = model(input, output, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask).transpose(0,1) #(batch_size, output_size, vocab_size)\n","\n","        # 현재(마지막) 시점의 예측 단어를 받아온다.\n","        predictions = predictions[:, -1:, :]\n","        predicted_id = torch.LongTensor(torch.argmax(predictions.cpu(), axis=-1))\n","\n","\n","        # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n","        if torch.equal(predicted_id[0][0], torch.tensor(END_TOKEN[0])):\n","            break\n","\n","        # 마지막 시점의 예측 단어를 출력에 연결한다.\n","        # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n","        output = torch.cat([output, predicted_id.to(device)], axis=1)\n","\n","    return torch.squeeze(output, axis=0).cpu().numpy()\n","\n","def predict(sentence):\n","    prediction = evaluate(sentence)\n","    predicted_sentence = vocab.Decode(list(map(int,[i for i in prediction if i < vocab_size])))\n","    \n","    print(\"========================================\")\n","    print('Q: {}'.format(sentence))\n","    print('A: {}'.format(predicted_sentence))\n"],"metadata":{"id":"9UV0NbRsd8Ih"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load(\"chatbot.pth\"))\n","result = predict(\"놀고싶다\")\n","result = predict(\"감기 같애\")\n","result = predict(\"건강하게 다이어트 하는 방법\")\n","result = predict(\"게임하고 싶어\")\n","result = predict(\"궁금하지?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hKRuSLuIe72k","executionInfo":{"status":"ok","timestamp":1676203310243,"user_tz":-540,"elapsed":2,"user":{"displayName":"김수영","userId":"09235899458207981129"}},"outputId":"6d5e6cfc-34c8-4c85-ec27-f1346b0ff232"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["========================================\n","Q: 놀고싶다\n","A: 저도 데려가세요 .\n","========================================\n","Q: 감기 같애\n","A: 병원가세요 .\n","========================================\n","Q: 건강하게 다이어트 하는 방법\n","A: 오늘 일찍 주무세요 .\n","========================================\n","Q: 게임하고 싶어\n","A: 지금도 늦지 않았어요 .\n","========================================\n","Q: 궁금하지?\n","A: 개인의 선택이죠 .\n"]}]}]}